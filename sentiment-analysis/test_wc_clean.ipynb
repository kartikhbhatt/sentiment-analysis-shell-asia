{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f449ae51",
   "metadata": {},
   "source": [
    "# Word Cloud and Sentiment Analysis\n",
    "\n",
    "This notebook contains code for generating word clouds and performing sentiment analysis on text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0018fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0726646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Replace 'your_file.csv' with your actual file path\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text data\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "# Replace 'content' with your actual column name\n",
    "df['cleaned_content'] = df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051017ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis function\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of text using TextBlob\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    if polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['sentiment'] = df['cleaned_content'].apply(get_sentiment)\n",
    "df['polarity'] = df['cleaned_content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Display sentiment distribution\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "def create_wordcloud(text, title=\"Word Cloud\"):\n",
    "    \"\"\"\n",
    "    Create and display word cloud\n",
    "    \"\"\"\n",
    "    # Combine all text\n",
    "    all_text = ' '.join(text.dropna())\n",
    "    \n",
    "    # Create word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white',\n",
    "        max_words=100,\n",
    "        colormap='viridis'\n",
    "    ).generate(all_text)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "# Create word clouds for different sentiments\n",
    "create_wordcloud(df['cleaned_content'], \"Overall Word Cloud\")\n",
    "create_wordcloud(df[df['sentiment'] == 'Positive']['cleaned_content'], \"Positive Sentiment Word Cloud\")\n",
    "create_wordcloud(df[df['sentiment'] == 'Negative']['cleaned_content'], \"Negative Sentiment Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a172a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Sentiment count plot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=df, x='sentiment', palette='viridis')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Polarity distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['polarity'], bins=30, alpha=0.7, color='skyblue')\n",
    "plt.title('Polarity Distribution')\n",
    "plt.xlabel('Polarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common words analysis\n",
    "def get_most_common_words(text_series, n=10):\n",
    "    \"\"\"\n",
    "    Get most common words from text series\n",
    "    \"\"\"\n",
    "    all_words = []\n",
    "    for text in text_series.dropna():\n",
    "        words = text.split()\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    # Filter out common stop words\n",
    "    stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them'}\n",
    "    \n",
    "    filtered_words = [word for word in all_words if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    return Counter(filtered_words).most_common(n)\n",
    "\n",
    "# Get most common words overall\n",
    "print(\"Most Common Words (Overall):\")\n",
    "common_words = get_most_common_words(df['cleaned_content'])\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Get most common words by sentiment\n",
    "print(\"\\nMost Common Words (Positive):\")\n",
    "positive_words = get_most_common_words(df[df['sentiment'] == 'Positive']['cleaned_content'])\n",
    "for word, count in positive_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nMost Common Words (Negative):\")\n",
    "negative_words = get_most_common_words(df[df['sentiment'] == 'Negative']['cleaned_content'])\n",
    "for word, count in negative_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a997318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "# Save processed data with sentiment scores\n",
    "df.to_csv('sentiment_analysis_results.csv', index=False)\n",
    "print(\"Results saved to 'sentiment_analysis_results.csv'\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Total texts analyzed: {len(df)}\")\n",
    "print(f\"Average polarity: {df['polarity'].mean():.3f}\")\n",
    "print(f\"Positive texts: {len(df[df['sentiment'] == 'Positive'])}\")\n",
    "print(f\"Negative texts: {len(df[df['sentiment'] == 'Negative'])}\")\n",
    "print(f\"Neutral texts: {len(df[df['sentiment'] == 'Neutral'])}\")\n",
    "print(f\"Most positive text: {df.loc[df['polarity'].idxmax()]['cleaned_content'][:100]}...\")\n",
    "print(f\"Most negative text: {df.loc[df['polarity'].idxmin()]['cleaned_content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
